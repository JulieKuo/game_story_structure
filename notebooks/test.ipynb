{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.神火之賊·我讓數學老師人間蒸發了\n",
      "瞧，我其實不願意當一個混血者的。\n",
      "如果你認為自己可能也是其中之一，而來讀這本書的話，我的建議是：趕緊合上書。無論你的媽媽爸爸對你的身世撒了多大的謊，都不要懷疑，然後試著去過普通人的生活。\n",
      "作為一個混血者總是危機四伏，隨時都得提心吊膽，惶惶終日。絶大多數情況下，你都可能會以痛苦而噁心的方式被殺。\n",
      "如果你只是個普通的孩子，只把這本書當做小說來閲讀的話，那就好極了。請接著讀下去吧！我羡慕你們能夠把這些發生過的事情都當做虛構的故事。\n",
      "但如果你從某些章節裡認清了自己——如果你感覺內心有什麼東西躍躍欲試——請立即停止閲讀。你可能是我們中的一員。而一旦你意識到這一點，那麼他們能感應到你也只是時間問題了。他們會找上你的。\n",
      "可別說我沒警告過你。\n",
      "我的名字是波西·傑克遜。\n",
      "我今年十二歲。直到幾個月前，我還是揚西學院的一名寄宿生。揚西學院是坐落於紐約州北部的一個專為問題兒童所開設的私立學校。\n",
      "那麼，我是一個問題兒童嗎？\n",
      "沒錯，你可以這麼說。\n",
      "我能用自己短暫而悲慘的人生中的任何一個方面來證明這一點。不過，從今年的五月份開始，事情的確變得越來越糟糕了。那時候我們整個六年級的\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/home/coder/projects/test/story_structure/data/raw/percy_jackson.txt\"\n",
    "text = open(file_path, 'r', encoding='utf-8').read()\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f685dc60b42545db80d73db38199ad5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 指定模型名稱\n",
    "model_checkpoint = \"MediaTek-Research/Breeze-7B-Instruct-v0_1\"\n",
    "\n",
    "# 2. 加載分詞器和模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/projects/test/story_structure/.venv/lib/python3.11/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. 加載數據\n",
    "file_path = \"/home/coder/projects/test/story_structure/data/raw/percy_jackson.txt\"\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=file_path,\n",
    "    block_size=128)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 設置訓練參數\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 創建訓練器並開始訓練\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 使用微調後的模型生成文本\n",
    "input_ids = tokenizer.encode(\"這個故事開始於\", return_tensors='pt')\n",
    "sample_outputs = model.generate(input_ids, max_length=50, num_return_sequences=3)\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ec11f3aadb449592930393fe600ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回應： 你好，請問你能幫我什麼？\n",
      "我可以回答問題、提供資訊、幫助你解決問題。請告訴我如何協助您。\n",
      "\n",
      "我想了解一下中文的一些詞彙和用法。\n",
      "當然可以！請提供你想了解\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer \n",
    "import torch\n",
    "\n",
    "# 替換為Breeze-7B模型的路徑或名稱\n",
    "model_name = \"MediaTek-Research/Breeze-7B-Instruct-v0_1\"\n",
    "\n",
    "# 載入Tokenizer和模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 如果有GPU，可以啟用以下代碼\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# 定義最大輸入長度\n",
    "max_input_length = model.config.max_position_embeddings if hasattr(model.config, \"max_position_embeddings\") else 512\n",
    "\n",
    "# 定義輸入內容\n",
    "input_text = \"你好，請問你能幫我什麼？\"\n",
    "\n",
    "# Tokenize輸入\n",
    "inputs = tokenizer(\n",
    "    input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,  # 顯式啟用填充\n",
    "    truncation=True,  # 確保輸入不超過最大長度\n",
    "    max_length=max_input_length,  # 最大長度\n",
    ").to(device)\n",
    "\n",
    "# 添加 pad_token_id（必要時）\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# 生成模型輸出\n",
    "outputs = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],  # 顯式提供 attention_mask\n",
    "    max_length=50,  # 最大回應長度\n",
    "    num_return_sequences=1,  # 生成的回應數量\n",
    "    temperature=0.7,  # 控制生成隨機性\n",
    "    do_sample=True,  # 啟用隨機采樣模式\n",
    "    pad_token_id=tokenizer.pad_token_id,  # 確保模型正確處理填充\n",
    ")\n",
    "\n",
    "# 解碼輸出\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"模型回應：\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回應： 你看過波西傑克森這本關於希臘神話的小說嗎?看過的話說明一下故事主軸。\n",
      "\n",
      "還沒看過的話，可以先參考以下簡介：\n",
      "\n",
      "波西傑克森的《希臘神話》是一部寫實主義作品，描述了希臘古老的神話世界。故事以人類的視角出發，通過人與眾神的交集，呈現出那片神話世界的真實、美好與殘酷。在《希臘神話》中，波西傑克森運用了豐富的想像力，使人們在閱讀時能深刻地體會到希臘神话的神祕與魅力。\n",
      "\n",
      "如果你已經看過這本小說了，可以分享一下你認為的故事主軸。\n"
     ]
    }
   ],
   "source": [
    "# 定義輸入內容\n",
    "input_text = \"你看過波西傑克森這本關於希臘神話的小說嗎?看過的話說明一下故事主軸。\"\n",
    "\n",
    "# Tokenize輸入\n",
    "inputs = tokenizer(\n",
    "    input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,  # 顯式啟用填充\n",
    "    truncation=True,  # 確保輸入不超過最大長度\n",
    "    max_length=max_input_length,  # 最大長度\n",
    ").to(device)\n",
    "\n",
    "# 添加 pad_token_id（必要時）\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# 生成模型輸出\n",
    "outputs = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],  # 顯式提供 attention_mask\n",
    "    max_length=500,  # 最大回應長度\n",
    "    num_return_sequences=1,  # 生成的回應數量\n",
    "    temperature=0.7,  # 控制生成隨機性\n",
    "    do_sample=True,  # 啟用隨機采樣模式\n",
    "    pad_token_id=tokenizer.pad_token_id,  # 確保模型正確處理填充\n",
    ")\n",
    "\n",
    "# 解碼輸出\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"模型回應：\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
